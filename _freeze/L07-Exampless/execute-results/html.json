{
  "hash": "5a7673c4b80ef174acca35248ad778f7",
  "result": {
    "markdown": "---\ntitle: \"ESS Exampless\"\ninstitute: \"**Jam TBD**\"\n---\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-1_a070d5f319b032b958832638fbfafd44'}\n\n```{.r .cell-code}\nset.seed(2112)\nlibrary(palmerpenguins)\npeng <- penguins[complete.cases(penguins), ]\nhead(peng)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           36.7          19.3               193        3450\n5 Adelie  Torgersen           39.3          20.6               190        3650\n6 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex <fct>, year <int>\n```\n:::\n:::\n\n\n## Review\n\nFrom last time, we basically learned what the following means:\n\n$$\n\\frac{SS(\\hat\\beta_{q+1}, ..., \\hat\\beta_p | \\hat\\beta_0, ... \\hat\\beta_q)}{(p-q)s^2} =\\frac{S_1 - S(\\hat\\beta_0) - (S_2 - S(\\hat\\beta_0))}{(p-q)s^2}\\sim F_{p-q, \\max(p, q)}\n$$ where $s^2$ is the MSE calculated from the larger model.\n\nThis allows us to do a test for whether $\\beta_{q+1} = \\beta_{q+2} = ... = \\beta_p = 0$.\n\nThe R code to do this test is as follows. In this code, we believe that the bill length and bill depth are strongly correlated, and thus we cannot trust the CIs that we get from `summary(lm())` (we saw \"Confidence Regions\" in the slides and code for L05).\n\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-2_a7a471b0f3596dea66363b632d5bf79e'}\n\n```{.r .cell-code}\nnrow(peng)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 333\n```\n:::\n:::\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-3_c4d1946f439a1edab0db525f1edff394'}\n\n```{.r .cell-code}\nlm1 <- lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm,\n    data = peng)\nlm2 <- lm(body_mass_g ~ flipper_length_mm,\n    data = peng)\nanova(lm2, lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: body_mass_g ~ flipper_length_mm\nModel 2: body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm\n  Res.Df      RSS Df Sum of Sq      F Pr(>F)\n1    331 51211963                           \n2    329 50814912  2    397051 1.2853 0.2779\n```\n:::\n:::\n\n\nLet's try and calculate these values ourselves in a couple different ways!\n\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-4_722b7fd594d918e6b0bc68af33368147'}\n\n```{.r .cell-code}\nanova(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: body_mass_g\n                   Df    Sum Sq   Mean Sq   F value Pr(>F)    \nflipper_length_mm   1 164047703 164047703 1062.1232 <2e-16 ***\nbill_length_mm      1    140000    140000    0.9064 0.3418    \nbill_depth_mm       1    257051    257051    1.6643 0.1979    \nResiduals         329  50814912    154453                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nFrom this model, SSE is 50814912 on 329 degrees of freedom. This is the same as the SSE in the output of `anova(lm2, lm1)`.\n\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-5_ed44ac3239574713f402bfd60abe55c6'}\n\n```{.r .cell-code}\nanova(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: body_mass_g\n                   Df    Sum Sq   Mean Sq F value    Pr(>F)    \nflipper_length_mm   1 164047703 164047703  1060.3 < 2.2e-16 ***\nResiduals         331  51211963    154719                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nAgain, the SSE of 51211963 matches what we saw in `anova(lm2, lm1)`, and we have 331 degrees of freedom (as expected, the differences in degrees of freedom is 2).\n\nNote that the F-value in `anova()` is just the ratio of the MSEs, but this is not the case here. Instead, we need to calculate $s^2$.\n\nWe can calculate $s^2$ as the MSE for the larger model:\n\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-6_679cdef5703d2ec6f94f99402c3dfed2'}\n\n```{.r .cell-code}\ns2 <- 50814912/329\ns2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 154452.6\n```\n:::\n:::\n\n\nAnd now we can calculate the F-value as expected:\n\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-7_6350f767ec2d2e6f71c503c127a60240'}\n\n```{.r .cell-code}\n(51211963 - 50814912)/ (2 * s2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.285349\n```\n:::\n:::\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-8_bfd8902a7704d9ff127fab72ce7ee8d9'}\n\n```{.r .cell-code}\nprint(1- pf(1.28539, 2, 329))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2779278\n```\n:::\n:::\n\n\nIt is left as an exercise to calculate these values based on matrix multiplication. I highly suggest trying it with and without correction factors to convince yourself that both of them work (and to convince yourself that you know what the correction factor is and why it's necessary).\n\n## ESS Algorithms\n\nThe idea above is based on testing a subset of predictors for at least one significant coefficient. This is usually what we want.\n\nHowever, there are also times where we want to check *all* predictors one-by-one. This is much less common than the textbook may lead you to believe, but it still happens.\n\nThere are three ways to calculate the ESS for *all* predictors. They are very helpfully labelled Types I, II, and III.\n\n-   Type I: Sequential Sum-of-Squares (with interactions)\n    -   Check $SS(\\hat\\beta_1|\\hat\\beta_0)$\n    -   Check $SS(\\hat\\beta_2|\\hat\\beta_0, \\hat\\beta_1)$\n    -   Check $SS(\\hat\\beta_2:\\hat\\beta_1|\\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_2)$\n        -   $\\hat\\beta_2:\\hat\\beta_1$ is an interaction term, which means we use a formula like `y ~ x1 + x2 + x1*x2` (although we'll learn why R uses different notation than this).\n    -   Check $SS(\\hat\\beta_3|\\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_2)$\n    -   Check all interactions between x1, x2, and x3,\n    -   ...\n\nThis will give us every possible sum-of-squares. This is very very dubious, and can lead to a multiple comparisons problem!\n\n-   Type 2: Sequential Sum-of-Squares (R's Default)\n    -   Check $SS(\\hat\\beta_1|\\hat\\beta_0)$\n    -   Check $SS(\\hat\\beta_2|\\hat\\beta_0, \\hat\\beta_1)$\n    -   Check $SS(\\hat\\beta_3|\\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_2)$\n    -   ...\n\nThis gives us an ordered sequence of \"is it worth adding x1?\", \"if we have x1, is it worth adding x2?\", etc. This is only meaningful if the predictors are naturally ordered (such as polynomial regression, see below).\n\n-   Type 3: Last-entry sum-of-squares\n    -   Check $SS(\\hat\\beta_1|\\hat\\beta_0, \\hat\\beta_2, \\hat\\beta_3)$\n    -   Check $SS(\\hat\\beta_2|\\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_3)$\n    -   Check $SS(\\hat\\beta_3|\\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_2)$\n\nThis checks whether adding predictor $x_i$ is worth it, considering all other predictors are already in the model.\n\n### Type 2 ANOVA (Sequental Sum-of-Squares)\n\nBy default, R does sequential sum-of-squares. This is a very important fact to know!\n\nIn Types I and II, *the order of the predictors matters*. In fact, you cannot make any conclusions about the significance that doesn't make reference to this fact.\n\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-9_9508506c38c18db560728d6d83c66fe5'}\n\n```{.r .cell-code}\n## Try changing the order to see how the significance changes!\nmylm <- lm(mpg ~ qsec + disp + wt, data = mtcars)\nanova(mylm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: mpg\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nqsec       1 197.39  197.39  28.276 1.165e-05 ***\ndisp       1 615.12  615.12  88.116 3.816e-10 ***\nwt         1 118.07  118.07  16.914 0.0003104 ***\nResiduals 28 195.46    6.98                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nsummary(mylm)$coef # No obvious connection to anova\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Estimate Std. Error     t value     Pr(>|t|)\n(Intercept) 19.7775575655 5.93828659  3.33051585 0.0024420674\nqsec         0.9266492353 0.34209668  2.70873496 0.0113897664\ndisp        -0.0001278962 0.01056025 -0.01211109 0.9904228666\nwt          -5.0344097167 1.22411993 -4.11267686 0.0003104157\n```\n:::\n:::\n\n\nHowever, there is at least one case where we do care about the order of the predictors. Consider **polynomial regression**, which we will return to later. For now, it is sufficient to know that we're dealing with the model: $$\ny_i = \\beta_0 + \\beta_1x_i + \\beta_2x_i^2 + \\beta_3x_i^3 + ... + \\beta_{p-1}x_i^{p-1} + \\epsilon_i\n$$In this model, notice that we only have one predictor $x$, but we have performed non-linear transformations (HMWK: why is it important that the transformations are non-linear?).\n\nIn this case, a sequential SS setup makes quite a bit of sense. Given we have a linear model, is it worth making it quadratic? Given that we have a quadratic model, is it worth making it cubic? Given that we have a cubic model...\n\nIn the code below, I use the `I()` function (the `I` means identity) to make the polynomial model. The \"formula\" notation in R, `y ~ x + z`, has a lot of options. Including `x^2`, rather than `I(x^2)`, makes R think we want to do one of the more fancy things, but the `I()` tells it that we want to literally square it. In the future, we'll use a better way of doing this.\n\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-10_4412b7b3c6fda0abfd8e0a4629627fd8'}\n\n```{.r .cell-code}\nx <- runif(600, 0, 20)\ny <- 2 - 3*x + 3*x^2 - 0.3*x^3 + rnorm(600, 0, 100)\nplot(y ~ x)\n```\n\n::: {.cell-output-display}\n![](L07-Exampless_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmylm <- lm(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6))\nanova(mylm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: y\n           Df   Sum Sq  Mean Sq   F value Pr(>F)    \nx           1 49560412 49560412 4726.8201 <2e-16 ***\nI(x^2)      1 19661307 19661307 1875.1955 <2e-16 ***\nI(x^3)      1  1150679  1150679  109.7459 <2e-16 ***\nI(x^4)      1      661      661    0.0630 0.8018    \nI(x^5)      1      112      112    0.0107 0.9177    \nI(x^6)      1     6274     6274    0.5984 0.4395    \nResiduals 593  6217568    10485                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nFrom the table above, we can clearly see that this should just be a cubic model (which is the true model that we generated). Try changing things around to see if, say, it will still detect an order 5 polynomial if if there's no terms of order 3 or 4.\n\n### A note on calculations\n\nTake a moment to consider the following. Suppose I checked the following two (Type II) ANOVA tables:\n\n-   `anova(lm(mpg ~ disp, data = mtcars))`\n-   `anova(lm(mpg ~ disp + wt, data = mtcars))`\n\nBoth tables will have the first row labelled \"disp\" and include its sum-of-squares along with the F-value. Do you expect these two rows to be the same?\n\nThink about it.\n\nThink a little more.\n\nWhat values do you expect to be used in the calculation?\n\nWhich sums-of-squares? Which variances?\n\nLet's test it out:\n\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-11_ae8312139a68498aae8a402012539ef8'}\n\n```{.r .cell-code}\nanova(lm(mpg ~ disp, data = mtcars))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: mpg\n          Df Sum Sq Mean Sq F value   Pr(>F)    \ndisp       1 808.89  808.89  76.513 9.38e-10 ***\nResiduals 30 317.16   10.57                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nanova(lm(mpg ~ disp + wt, data = mtcars))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: mpg\n          Df Sum Sq Mean Sq F value    Pr(>F)    \ndisp       1 808.89  808.89 95.0929 1.164e-10 ***\nwt         1  70.48   70.48  8.2852  0.007431 ** \nResiduals 29 246.68    8.51                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThey're different! As homework, find out where the F value for `disp` is coming from in both tables. (All required values are in the table, and the answer was stated earlier!)\n\nWith both the polynomial and the `disp` example, we see that the interpretation of the anova table is highly, extremely, extraordinarily dependent on which predictors we choose to include *AND* the order in which we choose to include them. So, yeah. Be careful.\n\n### Type III SS in R\n\nThere isn't a built-in function to do this. To create this, we can either use our math (my preferred method) or test each one individually.\n\n\n::: {.cell hash='L07-Exampless_cache/html/unnamed-chunk-12_507aa9991799e6900abb1cf0e487c3b2'}\n\n```{.r .cell-code}\nanova(\n    lm(mpg ~ disp + wt, data = mtcars),\n    lm(mpg ~ disp + wt + qsec, data = mtcars)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: mpg ~ disp + wt\nModel 2: mpg ~ disp + wt + qsec\n  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  \n1     29 246.68                              \n2     28 195.46  1     51.22 7.3372 0.01139 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nanova(\n    lm(mpg ~ disp + qsec, data = mtcars),\n    lm(mpg ~ disp + wt + qsec, data = mtcars)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: mpg ~ disp + qsec\nModel 2: mpg ~ disp + wt + qsec\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1     29 313.54                                  \n2     28 195.46  1    118.07 16.914 0.0003104 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nanova(\n    lm(mpg ~ wt + qsec, data = mtcars),\n    lm(mpg ~ disp + wt + qsec, data = mtcars)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: mpg ~ wt + qsec\nModel 2: mpg ~ disp + wt + qsec\n  Res.Df    RSS Df Sum of Sq     F Pr(>F)\n1     29 195.46                          \n2     28 195.46  1 0.0010239 1e-04 0.9904\n```\n:::\n:::\n\n\n## Modelling Strategies\n\nIf you are in a situation where you think to yourself \"my predictors are logically ordered and I want to check for the significance of all of them one-by-one\", you want Type II.\n\nIf you think \"they're not ordered but I want to check significance\", you might want to check the overall F test for all predictors and then check t-tests for individual parameters.\n\nIf you think \"what would happen if each predictor were the last one I put in the model\", then you want Type III. I can't think of a good situation for Type I - you're pretty much guaranteed to have a multiple comparisons issue.\n\nI also want to call attention to the fact that all of these algorithms assume that you have a set of predictors that you already know you want to check. If you noticed, there are other predictors in the mtcars dataset that we did not consider!\n\nWe'll slowly build up some intuition over time, but my advice for choosing which predictors to include is as follows:\n\n-   Start with a lot of plots.\n-   Based on the plots and your knowledge of the context, create a candidate set of predictors that you think will be the final model.\n-   Check the model fit (p-values, residuals, etc).\n-   Based on your knowledge of the context, check significance of groups of predictors that you think are highly correlated.\n-   Your final model will be based on the tests for groups of (or individual) predictors that you suspect would be relevant.\n\nThe purpose of this method for selecting predictors is to *minimize the number of p-values that you check*. The ESS techniques that we learned today (especially for the bill length/depth, where our knowledge of the problem informed us of which predictors to check) are an important part of the modelling process, but there is more to learn!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}