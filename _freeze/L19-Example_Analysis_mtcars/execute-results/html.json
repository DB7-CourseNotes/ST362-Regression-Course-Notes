{
  "hash": "fefcf295c486cd4fcceff569adf8c65e",
  "result": {
    "markdown": "---\ntitle: \"Analysis of MTCars\"\nauthor: \"Devan Becker\"\nformat: html\neditor: visual\n---\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-1_a126815cc1a0e47a8219188d3a9f1880'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\ntheme_set(theme_bw())\n```\n:::\n\n\n\n## Exploratory Data Analysis\n\n### Understanding Data\n\nWhat do the column names mean?\n\nThe help file gives a (very) brief description. I spent a few minutes just looking at the descriptions and trying to guess what relationships I might find.\n\nOverall, most of the predictors are trying to answer the question \"Is this a powerful car?\" \n\n### Plotting the Data\n\nFrom a pairs plot (`pairs(mtcars)`, which I have not included to reduce the amount of output):\n\n- Only 1 car has carb = 6, 1 has carb = 8\n- wt and drat are (-ively) correlated\n    - disp and hp\n    - disp and drat (-ive)\n    - disp and wt\n    - hp and wt \n    - hp and qsec\n\nwt and disp are clearly multicollinear, and they're measuring the same thing so I might want to include just one of them.\n\n### Patterns in the Predictors\n\nIn the following code, I tried x as am, cyl, gear, and carb. The y axis was wt, disp, drat, and qsec. I essentially tried every combination of these and wrote down the most interesting patterns. \n\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-2_1c76a6c83804888d32ebdb64f70d1ef7'}\n\n```{.r .cell-code}\n# Continuous versus categorical\nggplot(mtcars) +\n    aes(x = factor(am), y = wt) +\n    geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](L19-Example_Analysis_mtcars_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n- wt is different across categories of am, cyl, carb, gear (all positive)\n    - disp has same relationships\n    - hp has same relationships, except 4 gear cars have lower hp than 3 and 5 gear cars\n    - drat has opposite relationships\n    \nI did something similar with the following code, checking every combination of all relevant predictors and writing down anything that stuck out to me. \n    \n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-3_fcf25c327b87e0a017e9f1147f6c3ac0'}\n\n```{.r .cell-code}\n# Continuous vs. continuous\nggplot(mtcars) +\n    aes(x = disp, y = wt, colour = factor(cyl)) +\n    geom_point()\n```\n\n::: {.cell-output-display}\n![](L19-Example_Analysis_mtcars_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n- Clear separation between disp and wt when coloured by am or cyl.\n    - In other words, there are distinct groups. This probably means that one of the continuous predictors has all of the information necessary, and it won't be necessary to include an interaction between continuous predictors (it rarely is).\n- Otherwise, there are not many relationships that might be present.\n\n\nThe following plot was also used with all combinations of categorical predictors. \n\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-4_bc775aac5eada04af1cee7d48c313f01'}\n\n```{.r .cell-code}\n# categorical variables\nggplot(mtcars) + \n    aes(x = factor(am), fill = factor(vs)) +\n    geom_bar(position = \"dodge\")\n```\n\n::: {.cell-output-display}\n![](L19-Example_Analysis_mtcars_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n- Some kind of \"correlation\" between am and cyl.\n    - Measuring something similar, but from different perspectives.\n- Very little relation between am and vs - they're measuring different things.\n    - Might be worth checking models where am is switched with vs. \n\n### Conclusions\n\nMost things are measuring \"how powerful is this car\", so we should just choose the ones that make sense to us and check a few categorical predictors.\n\n`wt` and `disp` make the most sense as measures for `mpg`, and `am` and `cyl` also make some sense. I'll try switching out some of the other predictors, but I expect that the final model will either be `wt*am` or `disp*cyl`.\n\n## More EDA: Relationships with the Response / Interactions\n\n\nNow we're finally looking at mpg!\n\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-5_cc48424c482933c472068c7bb7e1009c'}\n\n```{.r .cell-code}\nggplot(mtcars) +\n    aes(y = mpg, x = disp, colour = factor(cyl)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = TRUE, formula = y ~ x)\n```\n\n::: {.cell-output-display}\n![](L19-Example_Analysis_mtcars_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nFrom looking at many many plots, I propose the following candidate models:\n\n- mpg versus disp * cyl\n- mpg versus wt * am (cyl?)\n- mpg versus wt * vs (maybe not an interaction)\n- mpg versus wt * gear?\n\nI had also considered including qsec, but a plot of mpg versus qsec with colours from cyl revealed that cyl explains the relationship; if we include cyl, then the slope for mpg versus qsec is 0. The same thing happens with drat, so cyl is probably enough to include in the model rather than either qsec or drat. \n\n\n## Modelling \n\nLet's test out our models!\n\nAgain, to reduce the amount of output I have to wade through, I changed the following code a bunch and left it at something meaningful to my final analysis.\n\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-6_47c55a1d4a59761a0b1d58e35d0acde7'}\n\n```{.r .cell-code}\ndispmodel <- lm(mpg ~ disp * factor(cyl), data = mtcars)\n\npar(mfrow = c(2,2))\nplot(dispmodel, col = mtcars$cyl)\n```\n\n::: {.cell-output-display}\n![](L19-Example_Analysis_mtcars_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n- Residuals versus fitted looks good\n- QQ norm looks great! For this small of a data set, we don't expect much from the qq-plot, so this is actually very nice.\n- Scale-Location has a slight U shape, which isn't ideal. There may still be a predictor that's worth including.\n- There's a high influence point. This is likely due to the interaction between cyl and disp.\n    - When we have this kind of interaction, there are essentially three lines, each with fewer observations. It is much easier for a point to be influential with interaction present. \n\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-7_f136be9d45d43baff0984dbbd28c1fe8'}\n\n```{.r .cell-code}\nwtmodel <- lm(mpg ~ wt * am, data = mtcars)\n\npar(mfrow = c(2,2))\nplot(wtmodel)\n```\n\n::: {.cell-output-display}\n![](L19-Example_Analysis_mtcars_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n- First plot looks good!\n- QQplot has some heavy tails - not bad, but not ideal. `dispmodel` was better.\n- Scale-location is great!\n- No high leverage points.\n\nBoth models are good in different ways. Let's check their summaries.\n\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-8_97a7836cbb5e1561734fc04eeb56ec73'}\n\n```{.r .cell-code}\nsummary(dispmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ disp * factor(cyl), data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4766 -1.8101 -0.2297  1.3523  5.0208 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        40.87196    3.02012  13.533 2.79e-13 ***\ndisp               -0.13514    0.02791  -4.842 5.10e-05 ***\nfactor(cyl)6      -21.78997    5.30660  -4.106 0.000354 ***\nfactor(cyl)8      -18.83916    4.61166  -4.085 0.000374 ***\ndisp:factor(cyl)6   0.13875    0.03635   3.817 0.000753 ***\ndisp:factor(cyl)8   0.11551    0.02955   3.909 0.000592 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.372 on 26 degrees of freedom\nMultiple R-squared:  0.8701,\tAdjusted R-squared:  0.8452 \nF-statistic: 34.84 on 5 and 26 DF,  p-value: 9.968e-11\n```\n:::\n:::\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-9_531d0cf7af3421cf87f414bb585b3bfc'}\n\n```{.r .cell-code}\nsummary(wtmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ wt * am, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6004 -1.5446 -0.5325  0.9012  6.0909 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  31.4161     3.0201  10.402 4.00e-11 ***\nwt           -3.7859     0.7856  -4.819 4.55e-05 ***\nam           14.8784     4.2640   3.489  0.00162 ** \nwt:am        -5.2984     1.4447  -3.667  0.00102 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.591 on 28 degrees of freedom\nMultiple R-squared:  0.833,\tAdjusted R-squared:  0.8151 \nF-statistic: 46.57 on 3 and 28 DF,  p-value: 5.209e-11\n```\n:::\n:::\n\n\nThe $R^2$ for `dispmodel` is a fair bit higher (although there's no standard for how much an $R^2$ should change, so this might not be a meaningful difference). As we saw in class, the $R^2$ is based on the same quantities as the F-test for different models. \n\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-10_12abc823795d47f01a08439df00eebc0'}\n\n```{.r .cell-code}\nanova(dispmodel, wtmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: mpg ~ disp * factor(cyl)\nModel 2: mpg ~ wt * am\n  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  \n1     26 146.23                              \n2     28 188.01 -2   -41.773 3.7136 0.03814 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThe models fit significantly differently. Which one fits better?\n\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-11_5a2e2845990abb635103d9046ad230c6'}\n\n```{.r .cell-code}\n# MSE values\nsummary(dispmodel)$sigma\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.371581\n```\n:::\n\n```{.r .cell-code}\nsummary(wtmodel)$sigma\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.591247\n```\n:::\n:::\n\n\n`dispmodel` has a higher $R^2$ and a lower MSE, so it seems to be the winner.\n\nFrom the pairs plot, I saw that disp has a slight relationship with other continuous predictors, and the scale-location plot wasn't perfect. Perhaps another predictor will help?\n\nI can do this with the magical `update()` function. The `~ . + hp` notation means the response versus (`~`) everything `.`, then add `hp`. The `~` means \"versus\" (with the response on the left, which isn't allowed to change in this case, and the predictors on the right), and the `.` means \"everything\", which in this case refers to everything that was already in the model. The form `lm(mpg ~ ., data = mtcars)` will fit mpg against everything else it sees in the mtcars dataset. \n\n\n::: {.cell hash='L19-Example_Analysis_mtcars_cache/html/unnamed-chunk-12_4def513cb4f832485854c554437866aa'}\n\n```{.r .cell-code}\nsummary(update(dispmodel, ~ . + hp)) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ disp + factor(cyl) + hp + disp:factor(cyl), \n    data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.3442 -1.7647  0.0994  1.4480  4.4796 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        41.53521    3.04752  13.629 4.48e-13 ***\ndisp               -0.13037    0.02798  -4.660 9.00e-05 ***\nfactor(cyl)6      -19.95406    5.48572  -3.637 0.001249 ** \nfactor(cyl)8      -16.99535    4.83011  -3.519 0.001685 ** \nhp                 -0.01410    0.01184  -1.191 0.245018    \ndisp:factor(cyl)6   0.12975    0.03685   3.521 0.001675 ** \ndisp:factor(cyl)8   0.11199    0.02946   3.801 0.000824 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.353 on 25 degrees of freedom\nMultiple R-squared:  0.8771,\tAdjusted R-squared:  0.8476 \nF-statistic: 29.74 on 6 and 25 DF,  p-value: 3.199e-10\n```\n:::\n:::\n\n\nI checked qsec, drat, and hp, and none seemed worth including in the model. I'll just leave it as is.\n\nTo interpret the model we must be careful about the interaction term!\n\n$$\nmpg = \\begin{cases}\n\\beta_0 + \\beta_1 disp & \\text{if }cyl == 4\\\\\n(\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_4) disp & \\text{if }cyl == 6\\\\\n(\\beta_0 + \\beta_3) + (\\beta_1 + \\beta_5) disp & \\text{if }cyl == 8\\\\\n\\end{cases}\n$$\n\n- For 4 cylinder cars, the baseline mpg is 40 and decreases by 0.135 for each one unit increase in disp.\n- For 6 cylinder cars, the baseline mpg is about 21.5 and isn't really related to the displacement.\n- For 8 cylinder cars, the baseline mpg is about 24.5 and decreases by about 0.02 for each one-unit increase in displacement.\n    - Note that displacement has really large units, so 0.02 over hundreds of one-unit increases is still a lot!\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}