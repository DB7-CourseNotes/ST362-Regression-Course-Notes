{
  "hash": "3a07334db41ff6da9660867db4ceadbf",
  "result": {
    "markdown": "---\ntitle: \"Extra Sum-of-Squares\"\ninstitute: \"**Jam TBD**\"\n---\n\n\n## Introduction\n\n### Today's Main Idea\n\nIf you add or remove predictors, the variance of the residuals changes!\n\n\\pspace\n\n- As always, we ask if it's a \"big\" change.\\lspace\n- Different predictors have a different effect on the residuals.\n\n\\pspace\\pause\n\nWhich predictors have a meaningful (significant?) effect on the residuals?\n\n### Sum-of-Squares due to Regression\n\n- Since SSE = SST - SSReg and SST never changes, we're focusing on SSReg.\\lspace\n- Recall: SSReg is the variance of the line itself!\n\n$$\nSSReg = \\sum_{i=1}^n(\\hat y_i - \\bar y)\n$$\n\n### SSReg in two different penguin models\n\nIn the `penguins` data, we're determining which predictors are associated with body mass.\n\n- $SS_1$ = SSReg for model 1\n    - $\\texttt{body\\_mass\\_g} = \\beta_0 + \\beta_1 \\texttt{flipper\\_length\\_mm} + \\beta_2 \\texttt{bill\\_length\\_mm} + \\beta_3 \\texttt{bill\\_depth\\_mm}$\n- $SS_2$ = SSReg for model 2\n    - $\\texttt{body\\_mass\\_g} = \\beta_0 + \\beta_1 \\texttt{flipper\\_length\\_mm} + \\beta_2 \\texttt{bill\\_length\\_mm}$\n\nNote: M2 is **nested** in M1 - M1 has all the same predictors and then some.\n\n\\pspace\n\n::: {.callout-important}\n$\\beta_1$ in the first model is **different** from $\\beta_1$ in the second model.\n:::\n\n### Extra Sum-of-Squares\n\nIf M2 is **nested** within M1, \\emph{e.g.}:\n\n- M1: $\\texttt{bodymass} = \\beta_0 + \\beta_1 \\texttt{flipperlength} + \\beta_2 \\texttt{billlength} + \\beta_3 \\texttt{billdepth}$\n- M2: $\\texttt{bodymass} = \\beta_0 + \\beta_1 \\texttt{flipperlength} + \\beta_2 \\texttt{billlength}$\n\nThen the Extra sum of squares is defined as:\n$$\nSS(\\hat\\beta_3 | \\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_2) = S_1 - S_2\n$$\n\n\\pspace\n\nConvince yourself that S1 > S2.\n\n### Special Case: Corrected Sum-of-Squares\n\nWe've already seen this notation:\n$$\nSSReg(\\hat\\beta_0) = n\\bar{\\underline y}^2\n$$\nand\n$$\nSSReg(corrected) = \\hat{\\underline\\beta}^TX^T\\underline y - n\\bar{\\underline y}^2 = S_1 - S_2\n$$\nwhere $S_2$ is the sum-of-squares for the null model!\n\n### Unspecial Case: Correction doesn't matter!\n\nConsider $S_{1c}$ and $S_{2c}$, the corrected versions of $S_1$ and $S_2$. Then\n\n\\begin{align*}\nS_{1c} - S_{2c} = (S_2 - n\\bar{\\underline y}^2) - (S_1 - n\\bar{\\underline y}^2) = S_1 - S_2\n\\end{align*}\n\n\\pspace\n\nIn other words, the correction term doesn't matter. \n\nThis is useful because R outputs the corrected versions.\n\n### Unspecial Case: SSReg versus SSE doesn't matter!\n\nConsider $SSE_1$ and $SSE_2$. Since SST is the same for both models,\n\n\\begin{align*}\nSSE_2 - SSE_1 = (SST - S_1) - (SST - S_2) = S_2 - S_1\n\\end{align*}\n\nNotice that the order is switched, which is fine.\n\n### ANOVA Tests for ESS\n\nConsider the models:\n\n- M1: $\\texttt{bodymass} = \\beta_0 + \\beta_1 \\texttt{flipperlength} + \\beta_2 \\texttt{billlength} + \\beta_3 \\texttt{billdepth}$\n    - $df_1 = 4$\n- M2: $\\texttt{bodymass} = \\beta_0 + \\beta_1 \\texttt{flipperlength} + \\beta_2 \\texttt{billlength}$\n    - $df_2 = 3$\n\n\\pspace\n\nIf we choose $H_0: \\beta_3 = 0$ in model 1, then\n$$\n\\frac{S_1 - S_2}{(4 - 3)s^2} \\sim F_{1,\\nu}\n$$\n\nwhere $s^2$ is the error variance (MSE) in the larger model with degress of freedom $\\nu = df_1$.\n\nThis is almost identical to the F-test for only one predictor (with one important difference).\n\n### In General\n\nIf M1 has $p$ df, M2 has $q$ df, and one is nested in the other, then $\\nu = \\max(p, q)$ and\n\n$$\n\\frac{S_1 - S_2}{(p - q)s^2} \\sim F_{|p-q|,\\nu}\n$$\n\n\\pspace\n\nNote that it doesn't matter which is nested: $S_1 - S_2$ has the same sign as $p-q$, so it's always positive.\n\n### Omnibus Tests for Multiple Predictors\n\nSuppose we want to test if *any* bill measurement is useful. \n\n- Bill length and depth are highly correlated - marginal CIs won't be valid.\n- Confidence Regions are hard (and only work in 2D)\n\n\\pspace\n\nInstead, we can use the ESS to test for a subset of predictors!\n\n- M1: $\\texttt{bodymass} = \\beta_0 + \\beta_1 \\texttt{flipperlength} + \\beta_2 \\texttt{billlength} + \\beta_3 \\texttt{billdepth}$\n- M2: $\\texttt{bodymass} = \\beta_0 + \\beta_1 \\texttt{flipperlength}$\n\n$S_1 = S_2$ is equivalent to $\\beta_2 = \\beta_3 = 0$, and it accounts for their covariance!\n\n\\pspace\n\nIf significant, then at least one of $(\\beta_2, \\beta_3)$ is not 0.\n\n### In R\n\n\n::: {.cell hash='L06-Extra_Sums_of_Squares-1_cache/html/unnamed-chunk-1_586de379356e3e98c5815e06117d3b3f'}\n\n```{.r .cell-code}\nlibrary(palmerpenguins)\npeng <- penguins[complete.cases(penguins),]\nm1 <- lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm,\n    data = peng)\nm2 <- lm(body_mass_g ~ flipper_length_mm,\n    data = peng)\nanova(m1, m2) |> knitr::kable()\n```\n\n::: {.cell-output-display}\n| Res.Df|      RSS| Df| Sum of Sq|        F|    Pr(>F)|\n|------:|--------:|--:|---------:|--------:|---------:|\n|    329| 50814912| NA|        NA|       NA|        NA|\n|    331| 51211963| -2| -397050.9| 1.285349| 0.2779392|\n:::\n:::\n\n\n### Next time\n\n- When to check ESS\\lspace\n- How to check all ESS\\lspace\n- What is R's `anova()` function even doing??\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}