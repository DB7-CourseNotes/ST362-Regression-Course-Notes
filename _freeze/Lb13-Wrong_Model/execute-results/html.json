{
  "hash": "dc2c982971d58f24cb2d4ce292edbbcb",
  "result": {
    "markdown": "# Lab Missing/Extra Predictors\n\n## Missing Predictors\n\n-   True model: $Y = X\\underline\\beta + X_2\\underline\\beta_2 + \\underline\\epsilon$\n-   Estimated model: $Y = X\\underline\\beta + \\underline\\epsilon$\n\nWe're going to do this a little differently than other days. Let's look at the penguins data again:\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-1_2f649ea311d4fe77e0f590ee508830e6'}\n\n```{.r .cell-code}\nset.seed(2121)\nlibrary(palmerpenguins)\n## Remove NAs and take continuous variables\npenguins <- subset(penguins, species == \"Chinstrap\")\npeng <- penguins[complete.cases(penguins), c(3, 4, 5, 6)]\n## Standardize the x values\n#peng[, 1:3] <- apply(peng[, 1:3], 2, scale)\nhead(peng)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 4\n  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n           <dbl>         <dbl>             <int>       <int>\n1           46.5          17.9               192        3500\n2           50            19.5               196        3900\n3           51.3          19.2               193        3650\n4           45.4          18.7               188        3525\n5           52.7          19.8               197        3725\n6           45.2          17.8               198        3950\n```\n:::\n:::\n\n\nLet's \"\"\"make\"\"\" a true model:\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-2_f24d904abcebd0e3c0f4f8ec0db75ac3'}\n\n```{.r .cell-code}\npenglm <- lm(body_mass_g ~ ., data = peng)\nbeta <- coef(penglm)\nsigma <- summary(penglm)$sigma\n\nbeta\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      (Intercept)    bill_length_mm     bill_depth_mm flipper_length_mm \n      -3157.53005          16.03916          91.51275          22.57975 \n```\n:::\n\n```{.r .cell-code}\nsigma\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 276.9998\n```\n:::\n:::\n\n\nWe'll use these values as if they are *population* values and forget that they were calculated from a sample.\n\n-   The x-values will stay the same, we'll simulate new $y$ values according to this model.\n-   The advantage of this approach is that the predictors retain any correlation that they had.\n\n## Simulating from the \"Right\" model\n\nLet's forget the actual values of `body_mass_g`, and pretend that this is the true relationship: $$\nbodymass = 4207 + 18*billlength + 35*billdepth + 711.5*flipperlength + \\epsilon\n$$ where $\\epsilon_i \\sim N(0, 393)$.\n\nWe can simulate from this as follows:\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-3_b62408368263b34b63e622cd55b61594'}\n\n```{.r .cell-code}\nX <- cbind(1, as.matrix(peng[, 1:3]))\nn <- nrow(X)\nbody_mass_g <- X %*% beta + rnorm(n, 0, sigma)\n\nunname(beta)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -3157.53005    16.03916    91.51275    22.57975\n```\n:::\n\n```{.r .cell-code}\nunname(coef(lm(body_mass_g ~ -1 + X)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -3311.31867    16.27829   120.41292    20.77560\n```\n:::\n\n```{.r .cell-code}\nunname(coef(lm(body_mass_g ~ X[, -1])))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -3311.31867    16.27829   120.41292    20.77560\n```\n:::\n:::\n\n\nNow let's do this 1000s of times!\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-4_ca158e275e1c03b6cce33ca712c3591c'}\n\n```{.r .cell-code}\nres <- matrix(ncol = 4, nrow = 0)\nfor (i in 1:10000) {\n    body_mass_g <- X %*% beta + rnorm(n, 0, sigma)\n    right_lm <- lm(body_mass_g ~ -1 + X)\n    res <- rbind(res, unname(coef(right_lm)))\n}\n\ndim(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10000     4\n```\n:::\n:::\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-5_b4be108b76c5b708704229c71e588e2b'}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nfor(i in 1:4) {\n    hist(beta[i] - res[, i], \n        main =paste0(\"Bias = \",round(beta[i], 2), \" - \", \n            round(mean(res[, i]), 2), \" = \", \n            round(beta[i] - mean(res[, i]), 2)))\n    abline(v = 0, col = 2, lwd = 2)\n}\n```\n\n::: {.cell-output-display}\n![](Lb13-Wrong_Model_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThis looks good- we simulated according to the values in `beta`, and we were able to recover them. We've also shown that the linear model is unbiased!\n\n## Estimating the Wrong Model - Too few predictors\n\nIn the following code, I remove the \"`flipper_length_mm`\" (the third predictor) by only taking the first three columns of `X`, which includes the column of 1s.\n\nI then fit the model without flipper length, which we've seen before is an important predictor!\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-6_f6887c30f1d2a361fdb8654f7ffec19a'}\n\n```{.r .cell-code}\nres_reduced <- matrix(ncol = 3, nrow = 0)\nX_reduced <- X[, 1:3] # Still includes column of 1s\nbeta_reduced <- beta[1:3]\nfor (i in 1:10000) {\n    # Simulate from the correct model\n    body_mass_g <- X %*% beta + rnorm(n, 0, sigma)\n    # Only estimate beta 0-3 (not beta4)\n    wrong_lm <- lm(body_mass_g ~ -1 + X_reduced)\n    res_reduced <- rbind(res_reduced, unname(coef(wrong_lm)))\n}\n\ndim(res_reduced)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10000     3\n```\n:::\n:::\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-7_2f7d5f3f0949664da5cb386841e67ae5'}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nfor(i in 1:3) {\n    bias <- beta[i] - res_reduced[, i]\n    hist(bias, \n        main =paste0(\"Bias = \",round(beta[i], 2), \" - \", \n            round(mean(res_reduced[, i]), 2), \" = \", \n            round(mean(bias), 2)),\n        xlim = range(0, bias))\n    abline(v = 0, col = 2, lwd = 2)\n}\n```\n\n::: {.cell-output-display}\n![](Lb13-Wrong_Model_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nEverything is biased! Since `flipper_length_mm` was an important predictor, the estimates from the other predictors are biased!\n\nHere's how I like to think of this: the machine is trying to learn a pattern using the predictors we give it. These other predictors are trying to pick up on as much pattern as possible. Without the true pattern, they have to adjust.\n\nA big part of this comes from the fact that there's correlation in the predictors. Since they're correlated, if one is missing then the others can find the pattern through their correlation. Instead of `flipper_length_mm` causing a change in body mass, `flipper_length_mm` is correlated with `bill_length_mm` and `bill_depth_mm`, which then affect `body_mass_g` in place of `flipper_length_m`'s affect. In other words, they're trying to make up for missing patterns through the correlation, like a game of telephone where information has been lost along the way.\n\n## Too Many Predictors\n\nWhat happens if we include predictors that *aren't* correlated with the response?\n\nBefore we run this code, what do you expect?\n\nRecall our results when $Y = X\\underline\\beta + X_2\\underline\\beta_2 + \\underline\\epsilon$:\n\n$$\n\\begin{align*}\nE(\\hat{\\underline\\beta}) &= E((X^TX)^{-1}X^TY)\\\\\n& = (X^TX)^{-1}X^T(X\\underline\\beta + X_2\\underline\\beta_2) \\\\\n& = (X^TX)^{-1}X^TX\\underline\\beta + (X^TX)^{-1}X^TX_2\\underline\\beta_2 \\\\\n&= \\underline\\beta+ (X^TX)^{-1}X^TX_2\\underline\\beta_2\\\\\n&= \\underline\\beta + A\\underline\\beta_2\n\\end{align*}\n$$\n\nThis isn't directly applicable, but might help you think about what happens when $\\underline\\beta$ is too big.\n\nSince we already have the objects created, let's pretend that `X_reduced` is correct.\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-8_fb13f5198d4eb29cf4b098bd1ca21511'}\n\n```{.r .cell-code}\nres <- matrix(ncol = 4, nrow = 0)\nX_reduced <- X[, 1:3] # Still includes column of 1s\nbeta_reduced <- beta[1:3]\nfor (i in 1:10000) {\n    # Simulate from the correct (smaller) model\n    body_mass_g <- X_reduced %*% beta_reduced + rnorm(n, 0, sigma)\n    # Estimate the wrong model\n    wrong_lm <- lm(body_mass_g ~ -1 + X)\n    res <- rbind(res, unname(coef(wrong_lm)))\n\n}\n\npar(mfrow = c(2, 2))\nfor(i in 1:3) {\n    bias <- beta_reduced[i] - res[, i]\n    hist(bias, \n        main =paste0(\"Bias = \",round(beta[i], 2), \" - \", \n            round(mean(res[, i]), 2), \" = \", \n            round(mean(bias), 2)),\n        xlim = range(0, bias))\n    abline(v = 0, col = 2, lwd = 2)\n}\n```\n\n::: {.cell-output-display}\n![](Lb13-Wrong_Model_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nIt's unbiased! In this case, the estimate of $\\beta$ for `flipper_length_mm` is 0, and it's successfully estimating this:\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-9_1a4788dfacaef8822ecd11a28ae4e72d'}\n\n```{.r .cell-code}\nhist(res[, 4])\n```\n\n::: {.cell-output-display}\n![](Lb13-Wrong_Model_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## Too many *and* too few\n\nSo let's get to the final case. As we know, bill length and bill depth are correlated:\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-10_ec561b5afe48d593a17f8f2113931f0a'}\n\n```{.r .cell-code}\ncor(X[, -1]) # correlation matrix, without column of 1s\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  bill_length_mm bill_depth_mm flipper_length_mm\nbill_length_mm         1.0000000     0.6535362         0.4716073\nbill_depth_mm          0.6535362     1.0000000         0.5801429\nflipper_length_mm      0.4716073     0.5801429         1.0000000\n```\n:::\n:::\n\n\nLet's simulate with the coefficient for bill depth as 0, but include it in the model.\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-11_0b298fb6447dfd54d53a8bb313d02179'}\n\n```{.r .cell-code}\nprint(beta)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      (Intercept)    bill_length_mm     bill_depth_mm flipper_length_mm \n      -3157.53005          16.03916          91.51275          22.57975 \n```\n:::\n\n```{.r .cell-code}\nprint(head(X))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       bill_length_mm bill_depth_mm flipper_length_mm\n[1,] 1           46.5          17.9               192\n[2,] 1           50.0          19.5               196\n[3,] 1           51.3          19.2               193\n[4,] 1           45.4          18.7               188\n[5,] 1           52.7          19.8               197\n[6,] 1           45.2          17.8               198\n```\n:::\n:::\n\n\nTo be clear:\n\n-   Data Generating Process: body mass = $\\beta_0$ + $\\beta_1$ bill length + $\\beta_3$ flipper length\n-   Estimating: body mass = $\\beta_0$ + $\\beta_2$ bill depth + $\\beta_3$ flipper length\n\n\n::: {.cell hash='Lb13-Wrong_Model_cache/html/unnamed-chunk-12_a2102f6f69835ba7ea11c83c4b855dc2'}\n\n```{.r .cell-code}\nres <- matrix(ncol = 3, nrow = 0)\nbeta_fewmany <- beta\nbeta_fewmany[3] <- 0 # True coefficient for depth is 0, length != 0\nX_fewmany <- X[, c(1, 3, 4)] # estimating depth, not length\n\nfor (i in 1:10000) {\n    # Simulate from the correct (smaller) model\n    body_mass_g <- X %*% beta_fewmany + rnorm(n, 0, sigma)\n    # Estimate the wrong model\n    wrong_lm <- lm(body_mass_g ~ -1 + X_fewmany)\n    res <- rbind(res, unname(coef(wrong_lm)))\n\n}\n\npar(mfrow = c(2, 2))\nhist(res[, 1],\n    main = paste0(\"bias=\", round(beta[1], 2),\n        \"-\", round(mean(res[, 1]), 2),\n        \"=\", round(beta[1] - mean(res[, 1]), 2)))\nabline(v = beta[1], col = 2, lwd = 2)\n\nhist(res[, 2])\nabline(v = 0, col = 2, lwd = 2)\n\nhist(res[, 3],\n    main = paste0(\"bias=\", round(beta[4], 2),\n        \"-\", round(mean(res[, 3]), 2),\n        \"=\", round(beta[4] - mean(res[, 3]), 2)))\nabline(v = beta[4], col = 2, lwd = 2)\n```\n\n::: {.cell-output-display}\n![](Lb13-Wrong_Model_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n-   It looks like flipper length is unbiased\n\n    -   Technically, it isn't, but in this case it's a small bias.\n    -   If we were primarily interested in flipper length, misspecifying bill length/depth isn't so bad.\n\n-   The estimate of bill_depth isn't 0, but also doesn't correspond to anything in the DGP!\n\n    -   It's called a \"proxy measure\", and the coefficient must be interpreted carefully.\n\n## Summary\n\nChoosing the right subset of predictors can be HARD!\n\n-   Missing predictors means your estimates are biased\n-   Too many predictors isn't as bad of an issue\n    -   Overfitting!\n-   The wrong subset means no relation to DGP\n    -   Can still give (nearly) unbiased estimates for predictors of interest.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}