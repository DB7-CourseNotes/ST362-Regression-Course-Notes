{
  "hash": "6036ffc23e03bd8e54d1364e9fc21f7b",
  "result": {
    "markdown": "# Lab Transformations\n\n## Finding a model for `mpg ~ disp`\n\n### Polynomial Models\n\nFirst, let's consider the polynomial models from previous lecture:\n\n\n::: {.cell hash='Lb15-Transformations_cache/html/unnamed-chunk-1_97b17a5b7a09ecf6ca09de93bf3336a3'}\n\n```{.r .cell-code}\nplot(mpg ~ disp, data = mtcars)\n```\n\n::: {.cell-output-display}\n![](Lb15-Transformations_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nA reasonable model for this looks to be $mpg_i = \\beta_0 + \\beta_1disp_i + \\beta_{11}disp_i^2$:\n\n\n::: {.cell hash='Lb15-Transformations_cache/html/unnamed-chunk-2_263e40c7dfb1b30479453515f000e881'}\n\n```{.r .cell-code}\nplot(mpg ~ disp, data = mtcars)\ndisp_seq <- seq(min(mtcars$disp), max(mtcars$disp), 0.1)\npoly_seq <- lm(mpg ~ poly(disp, 2), data = mtcars) |>\n    predict(newdata = list(disp = disp_seq))\nlines(disp_seq, poly_seq)\n```\n\n::: {.cell-output-display}\n![](Lb15-Transformations_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nIt fits! However, the point of the polynomial lecture was that polynomials are tempting, but must be justified by theory. I'm not sure it's reasonable to assume that the fuel efficiency is proportional to the square of the displacement.\n\nMaybe a transformation will help?\n\n### Transformations\n\nLet's try the two main transformations we talked about in class.\n\n\n::: {.cell hash='Lb15-Transformations_cache/html/unnamed-chunk-3_4436e9502b1e9754b93f20890ac6a52f'}\n\n```{.r .cell-code}\npar(mfrow = c(2,2))\ndisp_seq <- seq(min(mtcars$disp), max(mtcars$disp), 0.1)\nlm_seq <- lm(mpg ~ disp, data = mtcars) |>\n    predict(newdata = list(disp = disp_seq))\n\nplot(mpg ~ disp, data = mtcars,\n    main = \"Polynomial Model\")\npoly_seq <- lm(mpg ~ poly(disp, 2), data = mtcars) |>\n    predict(newdata = list(disp = disp_seq))\nlines(disp_seq, lm_seq, col = \"#4a4a4a\", lty = 2)\nlines(disp_seq, poly_seq, col = 2, lwd = 2)\n\nplot(sqrt(mpg) ~ disp, data = mtcars,\n    main = \"Square Root Transfomation\")\nsqrt_seq <- lm(sqrt(mpg) ~ disp, data = mtcars) |>\n    predict(newdata = list(disp = disp_seq))\nlines(disp_seq, sqrt(lm_seq), col = \"#4a4a4a\", lty = 2)\nlines(disp_seq, sqrt_seq, col = 2, lwd = 2)\n\nplot(log(mpg) ~ disp, data = mtcars,\n    main = \"Log Transfomation\")\nlog_seq <- lm(log(mpg) ~ disp, data = mtcars) |>\n    predict(newdata = list(disp = disp_seq))\nlines(disp_seq, log(lm_seq), col = \"#4a4a4a\", lty = 2)\nlines(disp_seq, log_seq, col = 2, lwd = 2)\n\nplot(exp(mpg) ~ disp, data = mtcars,\n    main = \"Exponential Transfomation\")\nexp_seq <- lm(exp(mpg) ~ disp, data = mtcars) |>\n    predict(newdata = list(disp = disp_seq))\nlines(disp_seq, exp(lm_seq), col = \"#4a4a4a\", lty = 2)\nlines(disp_seq, exp_seq, col = 2, lwd = 2)\n```\n\n::: {.cell-output-display}\n![](Lb15-Transformations_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nI also added the linear model, transformed to the scale of the data. Notice how the linear model is curved on these non-linear scales!\n\nIn the end, the log-transform is actually pretty good! Let's evaluate that one!\n\nI'm going to add `log_mpg` as a column in mtcars because we're only going to be working on that scale. With transformations, all of our assumptions about the residuals are on the transformed scale!!! This is important!!!\n\n\n::: {.cell hash='Lb15-Transformations_cache/html/unnamed-chunk-4_7f9418edfe289b61b6881673f0f9e860'}\n\n```{.r .cell-code}\nmtcars$log_mpg <- log(mtcars$mpg)\n\nlog_lm <- lm(log_mpg ~ disp, data = mtcars)\nraw_lm <- lm(mpg ~ disp, data = mtcars)\n\npar(mfrow = c(3,2), mar = c(3,3,2,2))\nplot(raw_lm, which = 1)\nplot(log_lm, which = 1)\nplot(raw_lm, which = 2)\nplot(log_lm, which = 2)\nplot(raw_lm, which = 3)\nplot(log_lm, which = 3)\n```\n\n::: {.cell-output-display}\n![](Lb15-Transformations_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n-   Resids versus fitted looks better for `log_lm`!\n-   Normal Q-Q looks about the same\n-   Scale-location looks better for `log_lm`!\n\nIt's worth noting that we always use \"fitted\" rather than, say, `disp`. When using a polynomial model, the fitted values go from the lowest to highest. For a positive coefficient for `disp^2`, this means that it starts from the lowest point in the parabola and goes upward in both directions! Keep that in mind when interpreting residual plots of polynomial functions!\n\n## The Box-Cox Transformation\n\n\n::: {.cell hash='Lb15-Transformations_cache/html/unnamed-chunk-5_acf1bb277f66a89cbb3af16c65c73e6a'}\n\n```{.r .cell-code}\nlibrary(MASS)\nboxcox(lm(mtcars$mpg ~ mtcars$disp), data = mtcars)\n```\n\n::: {.cell-output-display}\n![](Lb15-Transformations_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nSince 0 is the the top 5% of log-Likelihood values, the log transform is reasonable according to Box-Cox!\n\n\n::: {.cell hash='Lb15-Transformations_cache/html/unnamed-chunk-6_a756fc2561bcc65b85787ec36f00e022'}\n\n```{.r .cell-code}\nbc <- boxcox(lm(mtcars$mpg ~ mtcars$disp), data = mtcars, plotit = FALSE)\nprint(bc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$x\n [1] -2.0 -1.9 -1.8 -1.7 -1.6 -1.5 -1.4 -1.3 -1.2 -1.1 -1.0 -0.9 -0.8 -0.7 -0.6\n[16] -0.5 -0.4 -0.3 -0.2 -0.1  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9\n[31]  1.0  1.1  1.2  1.3  1.4  1.5  1.6  1.7  1.8  1.9  2.0\n\n$y\n [1] -3.57059866 -2.41311198 -1.29583952 -0.22262913  0.80247262  1.77526399\n [7]  2.69144571  3.54669319  4.33674248  5.05748822  5.70509010  6.27608329\n[13]  6.76748690  7.17690379  7.50260505  7.74359272  7.89963620  7.97127900\n[19]  7.95981574  7.86724092  7.69617369  7.44976444  7.13158953  6.74554135\n[25]  6.29571958  5.78632931  5.22158959  4.60565519  3.94255266  3.23613075\n[31]  2.49002447  1.70763143  0.89209868  0.04631829 -0.82707014 -1.72567168\n[37] -2.64732452 -3.59008589 -4.55221639 -5.53216368 -6.52854602\n```\n:::\n\n```{.r .cell-code}\nprint(paste0(\"Optimal value of lamba is: \", bc$x[which.max(bc$y)]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Optimal value of lamba is: -0.3\"\n```\n:::\n:::\n\n::: {.cell hash='Lb15-Transformations_cache/html/unnamed-chunk-7_ab9005d39d19a0f14f52616e845981ab'}\n\n```{.r .cell-code}\nmtcars$opt_mpg <- (mtcars$mpg^(-0.3) - 1)/0.3\n\noptimal_lm <- lm(opt_mpg ~ disp, data = mtcars)\nraw_lm <- lm(mpg ~ disp, data = mtcars)\n\npar(mfrow = c(3,2), mar = c(3,3,2,2))\nplot(log_lm, which = 1)\nplot(optimal_lm, which = 1)\nplot(log_lm, which = 2)\nplot(optimal_lm, which = 2)\nplot(log_lm, which = 3)\nplot(optimal_lm, which = 3)\n```\n\n::: {.cell-output-display}\n![](Lb15-Transformations_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nIt does look a little bit better, but the log is simpler to interpret and should probably be used.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}